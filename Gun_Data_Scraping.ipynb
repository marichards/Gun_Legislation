{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Gun Data\n",
    "\n",
    "The idea here is to grab data related to guns, namely:\n",
    "\n",
    "* How many people are victims of gun violence in each year, in each state?\n",
    "* What is the NRA rating for each senator in each (election) year?\n",
    "* Which senators get NRA endorsements each year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Get Gun Violence Data\n",
    "\n",
    "This is from a .csv file I got from the CDC....https://wonder.cdc.gov/controller/datarequest/D76;jsessionid=9F60FA0EE42118E226739764CB333F97\n",
    "\n",
    "I want to compare numbers with the data from this [site](https://everytownresearch.org/gun-violence-by-the-numbers/)\n",
    "\n",
    "For instance, there should be 13,000 gun homicides per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 896 entries, 0 to 895\n",
      "Data columns (total 8 columns):\n",
      "Notes         69 non-null object\n",
      "Year          827 non-null float64\n",
      "Year Code     827 non-null float64\n",
      "State         827 non-null object\n",
      "State Code    827 non-null float64\n",
      "Deaths        827 non-null float64\n",
      "Population    827 non-null float64\n",
      "Crude Rate    827 non-null object\n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 56.1+ KB\n",
      "None\n",
      "  Notes    Year  Year Code       State  State Code  Deaths  Population  \\\n",
      "0   NaN  1999.0     1999.0     Alabama         1.0   293.0   4430141.0   \n",
      "1   NaN  1999.0     1999.0      Alaska         2.0    27.0    624779.0   \n",
      "2   NaN  1999.0     1999.0     Arizona         4.0   303.0   5023823.0   \n",
      "3   NaN  1999.0     1999.0    Arkansas         5.0   118.0   2651860.0   \n",
      "4   NaN  1999.0     1999.0  California         6.0  1380.0  33499204.0   \n",
      "\n",
      "  Crude Rate  \n",
      "0        6.6  \n",
      "1        4.3  \n",
      "2        6.0  \n",
      "3        4.4  \n",
      "4        4.1  \n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "gun_deaths = pd.read_table(\"./Underlying_Cause_of_Death_1999-2016.txt\")\n",
    "print(gun_deaths.info())\n",
    "print(gun_deaths.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check with those per-year stats to see if it holds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year\n",
      "1999.0    10792.0\n",
      "2000.0    10760.0\n",
      "2001.0    11296.0\n",
      "2002.0    11788.0\n",
      "2003.0    11888.0\n",
      "2004.0    11596.0\n",
      "2005.0    12314.0\n",
      "2006.0    12765.0\n",
      "2007.0    12592.0\n",
      "2008.0    12161.0\n",
      "2009.0    11482.0\n",
      "2010.0    11045.0\n",
      "2011.0    11044.0\n",
      "2012.0    11593.0\n",
      "2013.0    11171.0\n",
      "2014.0    10965.0\n",
      "2015.0    12973.0\n",
      "2016.0    14394.0\n",
      "Name: Deaths, dtype: float64\n",
      "Mean since 1999: 11812\n"
     ]
    }
   ],
   "source": [
    "# Group by year\n",
    "print(gun_deaths.groupby('Year')['Deaths'].sum())\n",
    "print(\"Mean since 1999: {:0.0f}\".format(gun_deaths.groupby('Year')['Deaths'].sum().mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are a bit low, but they're pretty in line with what I'm looking for here. I think there might be some \"suppressed\" data; I'm not 100% sure. But this is data for Assault via discharge of firearms....on to the NRA data!\n",
    "\n",
    "## Part 2: Find NRA Ratings for each Senator by (election) Year\n",
    "\n",
    "There's a couple possible sources here:\n",
    "\n",
    "* [NRA site](https://www.nrapvf.org/grades/) (only problem: need membership to access archives!)\n",
    "* [VoteSmart](https://votesmart.org/interest-group/1034/national-rifle-association) (problem: need to pay at least $45 to access API)\n",
    "\n",
    "Based on this, I'm going to have to manually scrape VoteSmart; however, their URLs are somewhat nonsensical...I'll just hardcode them:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put together all the URLs\n",
    "# https://votesmart.org/interest-group/1034/rating/10252?p=2&of=#\n",
    "nra_2018 = 'https://votesmart.org/interest-group/1034/rating/10252'\n",
    "nra_2017 = 'https://votesmart.org/interest-group/1034/rating/9703'\n",
    "nra_2016 = 'https://votesmart.org/interest-group/1034/rating/10178'\n",
    "nra_2015 = 'https://votesmart.org/interest-group/1034/rating/7776'\n",
    "nra_2014 = 'https://votesmart.org/interest-group/1034/rating/7165'\n",
    "nra_2013 = 'https://votesmart.org/interest-group/1034/rating/8738'\n",
    "nra_2012 = 'https://votesmart.org/interest-group/1034/rating/8741'\n",
    "nra_2010 = 'https://votesmart.org/interest-group/1034/rating/8740'\n",
    "nra_2008 = 'https://votesmart.org/interest-group/1034/rating/8787'\n",
    "nra_2006 = 'https://votesmart.org/interest-group/1034/rating/8786'\n",
    "nra_2004 = 'https://votesmart.org/interest-group/1034/rating/8785'\n",
    "nra_2002 = 'https://votesmart.org/interest-group/1034/rating/8784'\n",
    "nra_2000 = 'https://votesmart.org/interest-group/1034/rating/8788'\n",
    "nra_1998 = 'https://votesmart.org/interest-group/1034/rating/8739'\n",
    "nra_1994 = 'https://votesmart.org/interest-group/1034/rating/82'\n",
    "\n",
    "all_nra = [nra_2018, nra_2017, nra_2016,\n",
    "           nra_2015, nra_2014, nra_2013,\n",
    "           nra_2012, nra_2010, nra_2008,\n",
    "           nra_2006, nra_2004, nra_2002,\n",
    "           nra_2000, nra_1998, nra_1994]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test out with 2018 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the results \n",
    "results = requests.get(nra_2018).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3']\n"
     ]
    }
   ],
   "source": [
    "# Try grabbing the list of items\n",
    "nra_soup = BeautifulSoup(results, 'html.parser')\n",
    "nra_pages = nra_soup.find('ul', {\"class\" : 'range'}).find_all('li')\n",
    "all_pages = [item.text.strip() for item in nra_pages]\n",
    "print(all_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n"
     ]
    }
   ],
   "source": [
    "# Grab the headline including the year\n",
    "year_headline = nra_soup.find('h4').text\n",
    "print(re.findall(r'\\d{4}',year_headline)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've now demonstrated that I can grab the pages; and \"1\" actually works for the main page too! Now to make sure I can pull the table correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GA\n",
      "State House\n",
      "111\n",
      "Geoff Cauble\n",
      "Republican\n",
      "86%\n",
      "GA\n",
      "State Senate\n",
      "17\n",
      "Brian Strickland\n",
      "Republican\n",
      "93%\n",
      "IL\n",
      "U.S. House\n",
      "12\n",
      "Michael Bost\n",
      "Republican\n",
      "93%\n",
      "IL\n",
      "U.S. House\n",
      "16\n",
      "Adam Kinzinger\n",
      "Republican\n",
      "93%\n"
     ]
    }
   ],
   "source": [
    "nra_table = nra_soup.find('table').find_all('tr')\n",
    "for row in nra_table[1:5]:\n",
    "    print(row.find_all('td')[0].text) # State\n",
    "    print(row.find_all('td')[1].text) # Office\n",
    "    print(row.find_all('td')[2].text) # District\n",
    "    print(row.find_all('td')[3].text) # Name\n",
    "    print(row.find_all('td')[4].text) # Party\n",
    "    print(row.find_all('td')[5].text) # Rating   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've now demonstrated that I can do any of these; I'm going to wrap them into functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for pulling out data for a given page/table\n",
    "def pullNraInfo(page):\n",
    "    \n",
    "    # Turn the page into soup\n",
    "    results = requests.get(page).text\n",
    "    nra_soup = BeautifulSoup(results, 'html.parser')\n",
    "    \n",
    "    # Find the table\n",
    "    nra_table = nra_soup.find('table').find_all('tr')[1:]\n",
    "    \n",
    "    # Pull out the useful quantities\n",
    "    state = [row.find_all('td')[0].text for row in nra_table]\n",
    "    office = [row.find_all('td')[1].text for row in nra_table]\n",
    "    name = [row.find_all('td')[3].text for row in nra_table]\n",
    "    rating = [row.find_all('td')[5].text.strip('%') for row in nra_table]\n",
    "    \n",
    "    # Combine into a data frame\n",
    "    nra_df = pd.DataFrame({'State' : state,\n",
    "                           'Office' : office,\n",
    "                           'Name' : name,\n",
    "                           'Rating' : rating})\n",
    "    \n",
    "    # Pull the year from the headline\n",
    "    year_headline = nra_soup.find('h4').text\n",
    "    this_year = re.findall(r'\\d{4}',year_headline)[0]\n",
    "    \n",
    "    # Broadcast it\n",
    "    nra_df['Year'] = int(this_year)\n",
    "    \n",
    "    return nra_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Name        Office Rating State  Year\n",
      "0      Geoff Cauble   State House     86    GA  2018\n",
      "1  Brian Strickland  State Senate     93    GA  2018\n",
      "2      Michael Bost    U.S. House     93    IL  2018\n",
      "3    Adam Kinzinger    U.S. House     93    IL  2018\n",
      "4      Darin LaHood    U.S. House     93    IL  2018\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 5 columns):\n",
      "Name      200 non-null object\n",
      "Office    200 non-null object\n",
      "Rating    200 non-null object\n",
      "State     200 non-null object\n",
      "Year      200 non-null int64\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 7.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Test it out\n",
    "test = pullNraInfo(nra_2018)\n",
    "print(test.head())\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works great for 1 page, but I need to assemble all the pages. I need to make multiple URLs per year, specifically:\n",
    "\n",
    "* Take the given URL for the year\n",
    "* Detect how many pages there are (or at least list them)\n",
    "* Create an augmented URL for each one\n",
    "* Output the list of URLs for each year\n",
    "\n",
    "This should be relatively simple; I'll try for 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3']\n",
      "['https://votesmart.org/interest-group/1034/rating/10252?p=1&of=#', 'https://votesmart.org/interest-group/1034/rating/10252?p=2&of=#', 'https://votesmart.org/interest-group/1034/rating/10252?p=3&of=#']\n"
     ]
    }
   ],
   "source": [
    "# Recall how to get 2018 pages\n",
    "results = requests.get(nra_2018).text\n",
    "nra_soup = BeautifulSoup(results, 'html.parser')\n",
    "nra_pages = nra_soup.find('ul', {\"class\" : 'range'}).find_all('li')\n",
    "all_pages = [item.text.strip() for item in nra_pages]\n",
    "print(all_pages)\n",
    "\n",
    "# Add the page and office number for each:\n",
    "all_2018_urls = [nra_2018 + '?p={}&of=#'.format(item) for item in all_pages]\n",
    "print(all_2018_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to really test, grab the data from all 3 pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 417 entries, 0 to 16\n",
      "Data columns (total 5 columns):\n",
      "Name      417 non-null object\n",
      "Office    417 non-null object\n",
      "Rating    417 non-null object\n",
      "State     417 non-null object\n",
      "Year      417 non-null int64\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 19.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Use the fxn above\n",
    "all_2018_dfs = [pullNraInfo(url) for url in all_2018_urls]\n",
    "\n",
    "# Concatenate and find info\n",
    "full_2018 = pd.concat(all_2018_dfs)\n",
    "print(full_2018.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all great! so now I just need to make that a function and test it again, then I can apply it to ALL the URLs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting all urls for a given year\n",
    "def expandUrls(orig_url):\n",
    "    \n",
    "    # Get the original url\n",
    "    results = requests.get(orig_url).text\n",
    "    nra_soup = BeautifulSoup(results, 'html.parser')\n",
    "    \n",
    "    # Use try/except to find extra pages\n",
    "    try:\n",
    "        nra_pages = nra_soup.find('ul', {\"class\" : 'range'}).find_all('li')\n",
    "        all_pages = [item.text.strip() for item in nra_pages]\n",
    "    \n",
    "        # Find the max page and make a range up to there\n",
    "        max_page = int(all_pages[-1])\n",
    "        print(max_page)\n",
    "        page_nums = list(range(1, max_page + 1))\n",
    "      \n",
    "        # Add the page and office number for each:\n",
    "        all_urls = [orig_url + '?p={}&of=#'.format(item) for item in page_nums]\n",
    "    \n",
    "    # Grab exception: 1 page\n",
    "    except:\n",
    "        all_urls = [orig_url]\n",
    "        print(1)\n",
    "        \n",
    "    return all_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://votesmart.org/interest-group/1034/rating/10252?p=1&of=#',\n",
       " 'https://votesmart.org/interest-group/1034/rating/10252?p=2&of=#',\n",
       " 'https://votesmart.org/interest-group/1034/rating/10252?p=3&of=#']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test it\n",
    "expandUrls(nra_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(expandUrls(nra_2013))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the full workflow:\n",
    "\n",
    "* Expand all the URLs to the full set (and check how many there are!)\n",
    "* For each URL, grab the rating info\n",
    "* Concatenate the data frames to get 1 big one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "6\n",
      "68\n",
      "6\n",
      "3\n",
      "1\n",
      "39\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "149\n"
     ]
    }
   ],
   "source": [
    "# Quick for-loop to get all the urls\n",
    "all_urls = []\n",
    "# Go until 2004\n",
    "for year in all_nra: \n",
    "    # Get the urls for that year\n",
    "    all_urls += expandUrls(year)\n",
    "    \n",
    "print(len(all_urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have all the URLs now; I now need to scrape all 150ish URLs for their data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.6 s, sys: 225 ms, total: 18.8 s\n",
      "Wall time: 12min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Try a list comprehension to get 201 data frames\n",
    "full_nra_df = [pullNraInfo(url) for url in all_urls]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That took a little while (I think like 5-10 min); I'm going to collapse this into one data frame, then pickle it so I don't have to do this again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate everything\n",
    "nra_all_years = pd.concat(full_nra_df)\n",
    "\n",
    "# Pickle it\n",
    "nra_all_years.to_pickle('nra_all_years.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 28089 entries, 0 to 192\n",
      "Data columns (total 5 columns):\n",
      "Name      28089 non-null object\n",
      "Office    28089 non-null object\n",
      "Rating    28089 non-null object\n",
      "State     28089 non-null object\n",
      "Year      28089 non-null int64\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "nra_all_years.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 244 entries, 15 to 65\n",
      "Data columns (total 5 columns):\n",
      "Name      244 non-null object\n",
      "Office    244 non-null object\n",
      "Rating    244 non-null object\n",
      "State     244 non-null object\n",
      "Year      244 non-null int64\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 11.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Screen out only senators for US\n",
    "nra_all_years[nra_all_years.Office == 'U.S. Senate'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
